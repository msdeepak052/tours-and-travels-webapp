pipeline {
    agent any

    parameters {
        string(name: 'IMAGE_TAG', defaultValue: '1.0.4', description: 'Tag of the Docker image')
        string(name: 'ECR_REPO', defaultValue: 'app/tour-travels-webapp', description: 'ECR repository name')
        string(name: 'AWS_REGION', defaultValue: 'ap-south-1', description: 'AWS Region')
        string(name: 'APP_NAME', defaultValue: 'tours-travels-webapp', description: 'Name of the application')
        booleanParam(name: 'FORCE_REINSTALL_MONITORING', defaultValue: true, description: 'Force reinstall monitoring stack')
    }

    environment {
        AWS_REGION = "${params.AWS_REGION}"
        ECR_REPO   = "${params.ECR_REPO}"
        IMAGE_TAG  = "${params.IMAGE_TAG}"
        APP_NAME   = "${params.APP_NAME}"
        KUBECONFIG = "/var/lib/jenkins/.kube/config"
        ARGOCD_NAMESPACE = "argocd"
        ARGOCD_VERSION = "v3.0.5"
        AWS_ACCOUNT_ID = sh(script: "aws sts get-caller-identity --query Account --output text", returnStdout: true).trim()
        EKS_CLUSTER_NAME = sh(
            script: """
                aws eks list-clusters --region ${AWS_REGION} --query "clusters[?contains(@, 'deepak')]" --output text | head -1
            """,
            returnStdout: true
        ).trim()
        GIT_REPO = "https://github.com/msdeepak052/tours-and-travels-webapp.git"
        GIT_PATH = "k8s-app-manifests"
    }

    stages {
        stage('Print Parameters') {
            steps {
                echo "=== PARAMETERS ==="
                echo "AWS_REGION: ${AWS_REGION}"
                echo "ECR_REPO: ${ECR_REPO}"
                echo "IMAGE_TAG: ${IMAGE_TAG}"
                echo "APP_NAME: ${APP_NAME}"
                echo "EKS_CLUSTER_NAME: ${EKS_CLUSTER_NAME}"
                sh "argocd version --client"
            }
        }
        
        stage('Git Checkout') {
            steps {
                git branch: 'main', url: "${GIT_REPO}"
            }
        }
        
        stage('Install Argo CD in Cluster') {
            steps {
                script {
                    // Configure kubectl
                    sh """
                        aws eks update-kubeconfig \
                        --name ${EKS_CLUSTER_NAME} \
                        --region ${AWS_REGION}
                    """

                    // Check if Argo CD is already installed
                    def argocdInstalled = sh(
                        script: """
                            if kubectl get deployment argocd-server -n ${ARGOCD_NAMESPACE} >/dev/null 2>&1; then
                                echo "true"
                            else
                                echo "false"
                            fi
                        """,
                        returnStdout: true
                    ).trim()

                    if (argocdInstalled == "false") {
                        echo "Installing Argo CD..."
                        // Create namespace if not exists
                        sh "kubectl create namespace ${ARGOCD_NAMESPACE} --dry-run=client -o yaml | kubectl apply -f -"

                        // Install Argo CD with ClusterIP
                        sh """
                            kubectl apply -n ${ARGOCD_NAMESPACE} -f \
                            https://raw.githubusercontent.com/argoproj/argo-cd/${ARGOCD_VERSION}/manifests/install.yaml
                            
                            # Patch service to ClusterIP
                            kubectl patch svc argocd-server -n ${ARGOCD_NAMESPACE} \
                            -p '{"spec": {"type": "ClusterIP"}}'
                        """

                        // Wait for Argo CD to be ready
                        sh """
                            kubectl wait --for=condition=available deployment/argocd-server \
                            -n ${ARGOCD_NAMESPACE} --timeout=300s
                        """
                    } else {
                        echo "Argo CD is already installed in namespace ${ARGOCD_NAMESPACE}"
                
                        // Check current service type and only patch if it's LoadBalancer
                        def currentServiceType = sh(
                            script: """
                                kubectl get svc argocd-server -n ${ARGOCD_NAMESPACE} -o jsonpath='{.spec.type}'
                            """,
                            returnStdout: true
                        ).trim()

                         if (currentServiceType == "LoadBalancer") {
                            echo "Patching Argo CD service from LoadBalancer to ClusterIP..."
                            sh """
                                kubectl patch svc argocd-server -n ${ARGOCD_NAMESPACE} \
                                -p '{"spec": {"type": "ClusterIP"}}'
                            """
                        } else {
                            echo "Argo CD service is already ${currentServiceType}, no need to patch"
                        }
                    }
                }
            }
        }

        stage('Configure Argo CD') {
            steps {
                script {
                    // Get admin password 
                    env.ARGOCD_PASSWORD = sh(
                        script: """
                            until kubectl -n ${ARGOCD_NAMESPACE} get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
                            do
                                sleep 5
                                echo "Waiting for Argo CD admin secret..."
                            done
                        """,
                        returnStdout: true
                    ).trim()

                    // Get server ClusterIP
                    env.ARGOCD_SERVER = sh(
                        script: """
                            kubectl get svc argocd-server -n ${ARGOCD_NAMESPACE} -o jsonpath='{.spec.clusterIP}'
                        """,
                        returnStdout: true
                    ).trim()

                    echo "Argo CD ClusterIP: ${env.ARGOCD_SERVER}"
                    echo "Argo CD Admin Password: ${env.ARGOCD_PASSWORD}"   
                }
            }
        }
        
        stage("Configure Prometheus & Grafana") {
            steps {
                script {                    
                    // Check if we should force reinstall
                    def forceReinstall = params.FORCE_REINSTALL_MONITORING ?: false
                    def monitoringInstalled = sh(
                        script: """
                            if helm status kube-prometheus-stack -n monitoring >/dev/null 2>&1; then
                                echo "true"
                            else
                                echo "false"
                            fi
                        """,
                        returnStdout: true
                    ).trim()
                    
                    if (monitoringInstalled == "true" && !forceReinstall) {
                        echo "Prometheus and Grafana are already installed, checking service types..."

                        def prometheusType = sh(
                            script: "kubectl get svc kube-prometheus-stack-prometheus -n monitoring -o jsonpath='{.spec.type}'",
                            returnStdout: true
                        ).trim()

                        def grafanaType = sh(
                            script: "kubectl get svc kube-prometheus-stack-grafana -n monitoring -o jsonpath='{.spec.type}'",
                            returnStdout: true
                        ).trim()

                        if (prometheusType == "LoadBalancer") {
                            echo "Changing Prometheus service type to ClusterIP..."
                            sh "kubectl patch svc kube-prometheus-stack-prometheus -n monitoring -p '{\"spec\": {\"type\": \"ClusterIP\"}}'"
                        }

                        if (grafanaType == "LoadBalancer") {
                            echo "Changing Grafana service type to ClusterIP..."
                            sh "kubectl patch svc kube-prometheus-stack-grafana -n monitoring -p '{\"spec\": {\"type\": \"ClusterIP\"}}'"
                        }
                    } else {
                        if (forceReinstall && monitoringInstalled == "true") {
                            echo "Force reinstall requested - uninstalling existing deployment..."
                            sh """
                                helm uninstall kube-prometheus-stack -n monitoring
                                kubectl delete crd alertmanagerconfigs.monitoring.coreos.com || true
                                kubectl delete crd alertmanagers.monitoring.coreos.com || true
                                kubectl delete crd podmonitors.monitoring.coreos.com || true
                                kubectl delete crd probes.monitoring.coreos.com || true
                                kubectl delete crd prometheuses.monitoring.coreos.com || true
                                kubectl delete crd prometheusrules.monitoring.coreos.com || true
                                kubectl delete crd servicemonitors.monitoring.coreos.com || true
                                kubectl delete crd thanosrulers.monitoring.coreos.com || true
                            """
                        }
                        
                        echo "Installing Prometheus and Grafana with ClusterIP..."
                        
                        // First update dependencies
                        sh """
                            helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
                            helm repo update
                        """
                        
                        // Create namespace if not exists
                        sh """
                            kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
                        """
                        
                        // Install with ClusterIP
                        sh """
                            helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
                                -n monitoring \
                                --version 45.7.1 \
                                --set prometheus.service.type=ClusterIP \
                                --set grafana.service.type=ClusterIP \
                                --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \
                                --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false \
                                --wait \
                                --timeout 10m
                        """
                        
                        // Verify installation
                        sh """
                            kubectl wait --for=condition=available deployment/kube-prometheus-stack-grafana -n monitoring --timeout=300s
                            kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus -n monitoring --timeout=300s
                        """
                    }
                    
                    // Get credentials (URLs won't be accessible directly now)
                    env.GRAFANA_PASSWORD = sh(
                        script: """
                            kubectl get secret --namespace monitoring kube-prometheus-stack-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
                        """,
                        returnStdout: true
                    ).trim()
                    
                    echo "Grafana Username: admin"
                    echo "Grafana Password: ${env.GRAFANA_PASSWORD}"
                }
            }
        }

       stage("Install AWS Load Balancer Controller and Ingress") {
            steps {
                script {
                    // Get AWS account ID
                    env.AWS_ACCOUNT_ID = sh(
                        script: "aws sts get-caller-identity --query Account --output text",
                        returnStdout: true
                    ).trim()
                    
                    // Check if AWS Load Balancer Controller is already installed via Helm
                    def albControllerInstalled = sh(
                        script: """
                            if helm status aws-load-balancer-controller -n kube-system >/dev/null 2>&1; then
                                echo "true"
                            else
                                echo "false"
                            fi
                        """,
                        returnStdout: true
                    ).trim()
        
                    if (albControllerInstalled == "true") {
                        echo "AWS Load Balancer Controller is already installed via Helm."
                        
                        // =============================================
                        // FIXED: Using custom policy instead of AWS-managed
                        // =============================================
                        sh """
                            # Create custom policy if it doesn't exist
                            if ! aws iam get-policy --policy-arn arn:aws:iam::${AWS_ACCOUNT_ID}:policy/ALBControllerCustomPolicy --region ${AWS_REGION} >/dev/null 2>&1; then
                                echo "Creating custom IAM policy..."
                                curl -s -o alb-policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json
                                aws iam create-policy \\
                                    --policy-name ALBControllerCustomPolicy \\
                                    --policy-document file://alb-policy.json \\
                                    --region ${AWS_REGION}
                                rm -f alb-policy.json
                            fi
                            
                            # Attach custom policy to the role
                            aws iam attach-role-policy \\
                                --policy-arn arn:aws:iam::${AWS_ACCOUNT_ID}:policy/ALBControllerCustomPolicy \\
                                --role-name eksctl-deepak-project1-cluster-addon-iamservi-Role1-oSbFXg8JipNM \\
                                --region ${AWS_REGION} || true
                        """
                        // =============================================
                        
                    } else {
                        echo "Installing AWS Load Balancer Controller..."
        
                        // Associate IAM OIDC provider
                        sh """
                            eksctl utils associate-iam-oidc-provider \\
                                --cluster ${EKS_CLUSTER_NAME} \\
                                --region ${AWS_REGION} \\
                                --approve
                        """
        
                        // Add EKS Helm repository
                        sh """
                            helm repo add eks https://aws.github.io/eks-charts || true
                            helm repo update
                        """
        
                        // =============================================
                        // FIXED: Create and use custom policy
                        // =============================================
                        sh """
                            # Download latest ALB controller policy
                            curl -s -o alb-policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json
                            
                            # Create custom policy
                            aws iam create-policy \\
                                --policy-name ALBControllerCustomPolicy \\
                                --policy-document file://alb-policy.json \\
                                --region ${AWS_REGION}
                            rm -f alb-policy.json
                        """
                        
                        // Get custom policy ARN
                        def policyArn = sh(
                            script: """
                                aws iam list-policies \\
                                    --query "Policies[?PolicyName=='ALBControllerCustomPolicy'].Arn" \\
                                    --output text --region ${AWS_REGION}
                            """,
                            returnStdout: true
                        ).trim()
                        // =============================================
        
                        // Create IAM role and service account
                        sh """
                            eksctl create iamserviceaccount \\
                                --cluster=${EKS_CLUSTER_NAME} \\
                                --namespace=kube-system \\
                                --name=aws-load-balancer-controller \\
                                --attach-policy-arn=${policyArn} \\
                                --override-existing-serviceaccounts \\
                                --region ${AWS_REGION} \\
                                --approve
                        """
        
                        // Install the Helm chart
                        sh """
                            helm install aws-load-balancer-controller eks/aws-load-balancer-controller \\
                                -n kube-system \\
                                --version 1.5.4 \\
                                --set clusterName=${EKS_CLUSTER_NAME} \\
                                --set serviceAccount.create=false \\
                                --set serviceAccount.name=aws-load-balancer-controller \\
                                --set extraEnvVars[0].name=AWS_REGION \\
                                --set extraEnvVars[0].value=${AWS_REGION} \\
                                --wait
                        """
                    }
        
                    // Wait until ready
                    timeout(time: 5, unit: 'MINUTES') {
                        waitUntil {
                            try {
                                def status = sh(
                                    script: """
                                        kubectl get deployment aws-load-balancer-controller -n kube-system -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0"
                                    """,
                                    returnStdout: true
                                ).trim()
                                return status.isInteger() && status.toInteger() >= 1
                            } catch (Exception e) {
                                echo "Waiting for controller to become ready..."
                                return false
                            }
                        }
                    }
        
                    // Verify controller logs
                    sh """
                        echo "=== Controller Logs ==="
                        kubectl logs -n kube-system deployment/aws-load-balancer-controller --tail=50 || true
                    """
        
                    // Get version information
                    def albVersion = sh(
                        script: """
                            kubectl get deployment aws-load-balancer-controller -n kube-system \\
                            -o jsonpath='{.spec.template.spec.containers[0].image}' | awk -F: '{print \$NF}'
                        """,
                        returnStdout: true
                    ).trim()
        
                    echo "✅ AWS Load Balancer Controller is running and healthy"
                    echo "Controller version: ${albVersion}"
        
                    // Display detailed information
                    sh """
                        echo "=== Controller Deployment Status ==="
                        kubectl get deployment aws-load-balancer-controller -n kube-system -o wide
        
                        echo "=== Controller Pods ==="
                        kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -o wide
        
                        echo "=== Service Account ==="
                        kubectl get serviceaccount aws-load-balancer-controller -n kube-system -o yaml
        
                        echo "=== IAM Role Annotations ==="
                        kubectl describe serviceaccount aws-load-balancer-controller -n kube-system | grep Annotations
                    """
                }
            }
        }
        stage("Image Tag update in Kubernetes manifests") {
            steps {
                script {
                    // Get ECR URL with error handling
                    def ecrUrl = sh(
                        script: "aws ecr describe-repositories --repository-names ${ECR_REPO} --region ${AWS_REGION} --query 'repositories[0].repositoryUri' --output text",
                        returnStdout: true
                    ).trim()

                    if (!ecrUrl) {
                        error("Failed to retrieve ECR URL for repository: ${ECR_REPO}")
                    }

                    env.IMAGE_URI = "${ecrUrl}:${IMAGE_TAG}"
                    env.ECR_IMAGE_NAME = "${env.IMAGE_URI}"
                    echo "ECR Image Name: ${env.ECR_IMAGE_NAME}"

                    dir('k8s-app-manifests') {
                        // Update image tag
                        sh """
                            sed -i.bak 's|image: .*|image: ${env.ECR_IMAGE_NAME}|' tours-travels-webapp-deployment.yml
                            
                            # Ensure service is ClusterIP
                            sed -i.bak 's/type: .*/type: ClusterIP/' tours-travels-webapp-service.yml
                        """
                        // Verify the changes
                        sh "grep 'image: ' tours-travels-webapp-deployment.yml"
                        sh "grep 'type: ' tours-travels-webapp-service.yml"
                    }
                }
            }
        }

        stage("Commit code changes and push to GitHub"){
            steps{
                script{
                    withCredentials([gitUsernamePassword(credentialsId: 'githubCreds', gitToolName: 'Default')]) {
                        sh """
                            git add .
                            git commit -m "Updated Image Tag in Kubernetes manifests to ${env.ECR_IMAGE_NAME} and set services to ClusterIP"
                            git push https://github.com/msdeepak052/tours-and-travels-webapp.git main
                        """
                    }
                }
            }
        }
    }

    post {
        always {
            script {
                echo "=== CLEANUP ==="
                deleteDir()
            }
        }
        
        success {
            script {
                echo "✅ DEPLOYMENT SUCCESSFUL"
                echo "Ingress URL: http://${env.INGRESS_HOSTNAME}"
                echo "Application: http://${env.INGRESS_HOSTNAME}"
                echo "Argo CD: http://${env.INGRESS_HOSTNAME}/argocd"
                echo "Grafana: http://${env.INGRESS_HOSTNAME}/grafana"
                echo "Prometheus: http://${env.INGRESS_HOSTNAME}/prometheus"
                
                echo "Argo CD Admin Password: ${env.ARGOCD_PASSWORD}"
                echo "Grafana Username: admin"
                echo "Grafana Password: ${env.GRAFANA_PASSWORD}"
            }
        }
        
        failure {
            script {
                echo "❌ DEPLOYMENT FAILED"
                echo "Check logs for details"
            }
        }
    }
}
